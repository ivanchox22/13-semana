# Control por Rechazo Activo de Perturbaciones (ADRC)

El Control por Rechazo Activo de Perturbaciones (ADRC, por sus siglas en ingl茅s *Active Disturbance Rejection Control*) es una t茅cnica avanzada de control que surge como una alternativa robusta al control PID tradicional. Desarrollado por el Dr. Zhiqiang Gao, el ADRC busca mitigar las limitaciones del PID, especialmente su dependencia de un modelo preciso de la planta y su sensibilidad a perturbaciones externas e incertidumbres internas. 

El ADRC se basa en tres pilares fundamentales:
1. **Estimaci贸n de perturbaciones**: Utiliza un Observador de Estados Extendido (ESO) para estimar y compensar perturbaciones en tiempo real.
2. **Independencia del modelo**: Requiere solo informaci贸n b谩sica del sistema, como su orden y ganancia nominal.
3. **Simplificaci贸n del dise帽o**: Transforma el sistema real en una planta nominal de f谩cil control.

Esta t茅cnica ha demostrado ser efectiva en aplicaciones de control de movimiento y procesos industriales, donde las perturbaciones y variaciones param茅tricas son comunes.

---
## Definiciones

>  **_ADRC (Active Disturbance Rejection Control)_**: Estrategia de control robusto que estima y cancela activamente perturbaciones mediante un observador de estados extendido (ESO), requiriendo m铆nimo conocimiento del modelo de la planta. Combina realimentaci贸n no lineal y compensaci贸n en tiempo real de incertidumbres.

>  **_Observador de Estados Extendido (ESO)_**: Componente clave del ADRC que expande el espacio de estados para incluir la "perturbaci贸n total" como estado adicional, permitiendo su estimaci贸n y posterior cancelaci贸n. Opera bajo el principio de que cualquier desviaci贸n del modelo nominal puede tratarse como perturbaci贸n.

>  **_Perturbaci贸n Total (蔚(t))_**: T茅rmino agregado que engloba din谩micas no modeladas, variaciones param茅tricas y perturbaciones externas. El ESO estima 蔚(t) como un estado extendido, simplificando el dise帽o del controlador.

>  **_Ley de Control ADRC_**:
> ```math
> u = \frac{u_0 - \hat{蔚}(t)}{b_0}
> ```
> donde \( u_0 \) es la se帽al de control nominal y \( b_0 \) la ganancia aproximada de la planta. Esta estructura transforma el sistema en una cascada de integradores.

>  **_Funci贸n fal(e, 伪, 未)_**: Funci贸n no lineal usada en NADRC para manejar errores grandes/peque帽os de forma diferenciada:
> ```python
> def fal(e, alpha, delta):
>     return e/(delta**(1-alpha)) if abs(e)<=delta else abs(e)**alpha*sign(e)
> ```

## Componentes del ADRC

El **Control por Rechazo Activo de Perturbaciones (ADRC)** se estructura en tres componentes fundamentales que trabajan sin茅rgicamente para lograr un control robusto independiente del modelo preciso de la planta. El **Generador de Trayectorias** transforma referencias abruptas en perfiles suaves, preservando los actuadores de esfuerzos bruscos. El **Observador de Estados Extendido (ESO)**, coraz贸n del ADRC, estima en tiempo real tanto los estados no medibles como las perturbaciones totales (internas y externas), agrup谩ndolas en una 煤nica se帽al a compensar. Finalmente, la **Ley de Control** combina realimentaci贸n de estados y cancelaci贸n activa de perturbaciones, simplificando el sistema a una cadena de integradores nominales. Esta arquitectura permite controlar sistemas complejos con s贸lo conocer su orden din谩mico y una aproximaci贸n gruesa de su ganancia, demostrando especial eficacia en sistemas no lineales, de par谩metros variables o bajo perturbaciones significativas, superando as铆 limitaciones cl谩sicas del control PID tradicional.

### 1. Generador de Trayectorias
Define la referencia deseada para el sistema. Ejemplo:

Para un sistema de segundo orden, el generador puede ser:  

#### 1.1 Formulaci贸n Matem谩tica
```math
\begin{aligned}
&\text{Sistema de 2do orden:} \\
&\ddot{y}^* + 2\zeta\omega_n\dot{y}^* + \omega_n^2y^* = \omega_n^2r(t) \\
&\text{Donde:} \\
&\quad \omega_n = \text{Frecuencia natural} \\
&\quad \zeta = \text{Factor de amortiguamiento}
\end{aligned}
```

#### 1.1 Implementaci贸n en Python

```math
import numpy as np

def generate_trajectory(t, r, wn, zeta):
    """Genera trayectoria suavizada para referencia escal贸n"""
    y = np.zeros_like(t)
    yd = np.zeros_like(t)
    ydd = np.zeros_like(t)
    
    for i in range(1, len(t)):
        dt = t[i] - t[i-1]
        ydd[i] = wn**2*(r[i] - y[i-1]) - 2*zeta*wn*yd[i-1]
        yd[i] = yd[i-1] + ydd[i]*dt
        y[i] = y[i-1] + yd[i]*dt
        
    return y, yd, ydd
```

#### 1.2 Ejemplo de Uso




### 2. Observador de Estados Extendido (ESO)
Estima estados no medibles y perturbaciones. Para un sistema lineal:  
\[
\begin{cases} 
\dot{z}_1 = z_2 + L_1(y - z_1) \\ 
\dot{z}_2 = z_3 + b_0 u + L_2(y - z_1) \\ 
\dot{z}_3 = L_3(y - z_1) 
\end{cases}
\]  
Aqu铆, \( z_3 \) estima la "perturbaci贸n total" \( \epsilon(t) \).

### 3. Ley de Control
Combina realimentaci贸n de estados y compensaci贸n de perturbaciones:  
\[ u = \frac{u_0 - z_3}{b_0}, \quad u_0 = k_1(y^* - z_1) - k_2 z_2 \]

---

## Ejercicios Resueltos

### Ejercicio 1: Dise帽o de un ADRC para un sistema masa-resorte-amortiguador
**Planta**:  
\[ M\ddot{y} + B\dot{y} + Ky = u(t) + w(t) \]  
**Paso 1**: Reformular como:  
\[ \ddot{y} = \frac{u}{M} + \epsilon(t), \quad \epsilon(t) = -\frac{B}{M}\dot{y} - \frac{K}{M}y + w(t) \]  
**Paso 2**: Dise帽ar ESO para estimar \( \epsilon(t) \).  
**Paso 3**: Implementar la ley de control con polos en \( s = -15 \) (cr铆ticamente amortiguado).

---

## Ejercicios Adicionales

### Ejercicio 2: Sistema no lineal
Dado el sistema:  
\[ \dot{y} = -a_1 y - a_0 y^3 + b u \]  
1. Linealizar alrededor de un punto de operaci贸n.  
2. Dise帽ar un ADRC no lineal (NADRC) usando la funci贸n `fal(e, 伪, 未)`.  

### Ejercicio 3: Variaci贸n param茅trica
Simular un ADRC para:  
\[ \ddot{y} = (4.75 - 4.5y)u + 0.7\dot{y} - 0.25y \]  
Evaluar desempe帽o con perturbaciones en rampa y sinusoidal.

---

## Conclusiones

- El ADRC ofrece robustez frente a incertidumbres y perturbaciones, superando limitaciones del PID.  
- Su implementaci贸n requiere sintonizar menos par谩metros que un controlador convencional.  
- Aplicaciones industriales incluyen rob贸tica, control de motores y procesos qu铆micos.  

**Desaf铆os**:  
- Complejidad computacional en sistemas de alto orden.  
- Requiere ajuste cuidadoso del ESO para evitar ruido en la estimaci贸n.  

---

## Referencias

1. Gao, Z. (2014). *Active Disturbance Rejection Control: A Paradigm Shift in Feedback Control Design*. IEEE.  
2. Universidad ECCI. (2025). *Material del curso Control de Movimiento*.  
3. Guo, B. Z., & Zhao, Z. L. (2016). *On Convergence of Nonlinear Active Disturbance Rejection Control*. SIAM Journal on Control and Optimization.  
